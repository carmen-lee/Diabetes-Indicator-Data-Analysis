{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import Libraries'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Read Data'''\n",
    "data = pd.read_csv('diabetes_binary_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253680, 20) (253680,)\n"
     ]
    }
   ],
   "source": [
    "'''Prep Data'''\n",
    "\n",
    "# Generate dependent variable\n",
    "y = data.iloc[:,0]\n",
    "# Generate matrix of features\n",
    "X = data.iloc[:,1:-1]\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "'''Splitting dataset into training and testing dataset''' \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=38)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Performing Feature Scaling'''\n",
    "# Normalization is used only when our dataset follows a normal distribution (-1 to +1)\n",
    "# while standardization is a universal technique that can be used for any dataset irrespective of the distribution (-3 to +3)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training Artificial Neural Network'''\n",
    "# !! experiment with the value\n",
    "number_of_nodes = 6\n",
    "\n",
    "def keras_model(number_of_nodes):\n",
    "    #initialize ANN\n",
    "    ann = tf.keras.models.Sequential()\n",
    "\n",
    "    # architecture: 2 hidden layers, 1 input layer, and 1 output layer\n",
    "\n",
    "    # first hidden layer\n",
    "    ann.add(tf.keras.layers.Dense(units=number_of_nodes,activation=\"relu\"))\n",
    "\n",
    "    # second hidden layer\n",
    "    ann.add(tf.keras.layers.Dense(units=number_of_nodes,activation=\"relu\"))\n",
    "\n",
    "    # output layer\n",
    "    # two classes as output (0 or 1) => one node\n",
    "    # binary classification => sigmoid activation function\n",
    "    ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "    \n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 12:21:16.019506: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4250/4250 [==============================] - 18s 4ms/step - loss: 0.3324 - accuracy: 0.8604 - val_loss: 0.3138 - val_accuracy: 0.8662\n",
      "Epoch 2/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3203 - accuracy: 0.8635 - val_loss: 0.3116 - val_accuracy: 0.8665\n",
      "Epoch 3/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3185 - accuracy: 0.8638 - val_loss: 0.3113 - val_accuracy: 0.8688\n",
      "Epoch 4/100\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3176 - accuracy: 0.8647 - val_loss: 0.3095 - val_accuracy: 0.8684\n",
      "Epoch 5/100\n",
      "4250/4250 [==============================] - 19s 4ms/step - loss: 0.3173 - accuracy: 0.8649 - val_loss: 0.3092 - val_accuracy: 0.8684\n",
      "Epoch 6/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3170 - accuracy: 0.8650 - val_loss: 0.3092 - val_accuracy: 0.8690\n",
      "Epoch 7/100\n",
      "4250/4250 [==============================] - 20s 5ms/step - loss: 0.3169 - accuracy: 0.8650 - val_loss: 0.3093 - val_accuracy: 0.8685\n",
      "Epoch 8/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3166 - accuracy: 0.8653 - val_loss: 0.3090 - val_accuracy: 0.8692\n",
      "Epoch 9/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3166 - accuracy: 0.8651 - val_loss: 0.3094 - val_accuracy: 0.8692\n",
      "Epoch 10/100\n",
      "4250/4250 [==============================] - 21s 5ms/step - loss: 0.3164 - accuracy: 0.8654 - val_loss: 0.3092 - val_accuracy: 0.8681\n",
      "Epoch 11/100\n",
      "4250/4250 [==============================] - 28s 6ms/step - loss: 0.3164 - accuracy: 0.8652 - val_loss: 0.3091 - val_accuracy: 0.8692\n",
      "Epoch 12/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3162 - accuracy: 0.8653 - val_loss: 0.3089 - val_accuracy: 0.8691\n",
      "Epoch 13/100\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3161 - accuracy: 0.8656 - val_loss: 0.3095 - val_accuracy: 0.8680\n",
      "Epoch 14/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3160 - accuracy: 0.8657 - val_loss: 0.3092 - val_accuracy: 0.8681\n",
      "Epoch 15/100\n",
      "4250/4250 [==============================] - 18s 4ms/step - loss: 0.3160 - accuracy: 0.8656 - val_loss: 0.3088 - val_accuracy: 0.8688\n",
      "Epoch 16/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3159 - accuracy: 0.8655 - val_loss: 0.3092 - val_accuracy: 0.8686\n",
      "Epoch 17/100\n",
      "4250/4250 [==============================] - 28s 6ms/step - loss: 0.3159 - accuracy: 0.8656 - val_loss: 0.3089 - val_accuracy: 0.8686\n",
      "Epoch 18/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3157 - accuracy: 0.8654 - val_loss: 0.3100 - val_accuracy: 0.8684\n",
      "Epoch 19/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3157 - accuracy: 0.8657 - val_loss: 0.3086 - val_accuracy: 0.8684\n",
      "Epoch 20/100\n",
      "4250/4250 [==============================] - 15s 3ms/step - loss: 0.3157 - accuracy: 0.8656 - val_loss: 0.3096 - val_accuracy: 0.8685\n",
      "Epoch 21/100\n",
      "4250/4250 [==============================] - 20s 5ms/step - loss: 0.3157 - accuracy: 0.8656 - val_loss: 0.3089 - val_accuracy: 0.8686\n",
      "Epoch 22/100\n",
      "4250/4250 [==============================] - 22s 5ms/step - loss: 0.3156 - accuracy: 0.8659 - val_loss: 0.3095 - val_accuracy: 0.8689\n",
      "Epoch 23/100\n",
      "4250/4250 [==============================] - 20s 5ms/step - loss: 0.3155 - accuracy: 0.8654 - val_loss: 0.3086 - val_accuracy: 0.8687\n",
      "Epoch 24/100\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3156 - accuracy: 0.8661 - val_loss: 0.3088 - val_accuracy: 0.8683\n",
      "Epoch 25/100\n",
      "4250/4250 [==============================] - 21s 5ms/step - loss: 0.3156 - accuracy: 0.8656 - val_loss: 0.3087 - val_accuracy: 0.8685\n",
      "Epoch 26/100\n",
      "4250/4250 [==============================] - 27s 6ms/step - loss: 0.3156 - accuracy: 0.8655 - val_loss: 0.3085 - val_accuracy: 0.8688\n",
      "Epoch 27/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3154 - accuracy: 0.8660 - val_loss: 0.3089 - val_accuracy: 0.8688\n",
      "Epoch 28/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3154 - accuracy: 0.8656 - val_loss: 0.3086 - val_accuracy: 0.8688\n",
      "Epoch 29/100\n",
      "4250/4250 [==============================] - 19s 4ms/step - loss: 0.3154 - accuracy: 0.8658 - val_loss: 0.3088 - val_accuracy: 0.8688\n",
      "Epoch 30/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3154 - accuracy: 0.8659 - val_loss: 0.3089 - val_accuracy: 0.8690\n",
      "Epoch 31/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3154 - accuracy: 0.8659 - val_loss: 0.3087 - val_accuracy: 0.8687\n",
      "Epoch 32/100\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3154 - accuracy: 0.8657 - val_loss: 0.3089 - val_accuracy: 0.8683\n",
      "Epoch 33/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3153 - accuracy: 0.8659 - val_loss: 0.3090 - val_accuracy: 0.8688\n",
      "Epoch 34/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3153 - accuracy: 0.8658 - val_loss: 0.3087 - val_accuracy: 0.8688\n",
      "Epoch 35/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3152 - accuracy: 0.8658 - val_loss: 0.3086 - val_accuracy: 0.8691\n",
      "Epoch 36/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3152 - accuracy: 0.8656 - val_loss: 0.3088 - val_accuracy: 0.8686\n",
      "Epoch 37/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3153 - accuracy: 0.8657 - val_loss: 0.3087 - val_accuracy: 0.8689\n",
      "Epoch 38/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3152 - accuracy: 0.8659 - val_loss: 0.3090 - val_accuracy: 0.8685\n",
      "Epoch 39/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3152 - accuracy: 0.8658 - val_loss: 0.3086 - val_accuracy: 0.8687\n",
      "Epoch 40/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3152 - accuracy: 0.8659 - val_loss: 0.3087 - val_accuracy: 0.8687\n",
      "Epoch 41/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3152 - accuracy: 0.8656 - val_loss: 0.3095 - val_accuracy: 0.8688\n",
      "Epoch 42/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3152 - accuracy: 0.8657 - val_loss: 0.3085 - val_accuracy: 0.8688\n",
      "Epoch 43/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3151 - accuracy: 0.8660 - val_loss: 0.3085 - val_accuracy: 0.8687\n",
      "Epoch 44/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3152 - accuracy: 0.8653 - val_loss: 0.3089 - val_accuracy: 0.8683\n",
      "Epoch 45/100\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3152 - accuracy: 0.8655 - val_loss: 0.3087 - val_accuracy: 0.8689\n",
      "Epoch 46/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3151 - accuracy: 0.8660 - val_loss: 0.3089 - val_accuracy: 0.8684\n",
      "Epoch 47/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3151 - accuracy: 0.8659 - val_loss: 0.3099 - val_accuracy: 0.8687\n",
      "Epoch 48/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3151 - accuracy: 0.8658 - val_loss: 0.3087 - val_accuracy: 0.8688\n",
      "Epoch 49/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3152 - accuracy: 0.8659 - val_loss: 0.3094 - val_accuracy: 0.8689\n",
      "Epoch 50/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3151 - accuracy: 0.8656 - val_loss: 0.3085 - val_accuracy: 0.8687\n",
      "Epoch 51/100\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.3151 - accuracy: 0.8657 - val_loss: 0.3086 - val_accuracy: 0.8684\n",
      "Epoch 52/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3151 - accuracy: 0.8661 - val_loss: 0.3088 - val_accuracy: 0.8687\n",
      "Epoch 53/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3150 - accuracy: 0.8658 - val_loss: 0.3087 - val_accuracy: 0.8686\n",
      "Epoch 54/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3151 - accuracy: 0.8658 - val_loss: 0.3088 - val_accuracy: 0.8687\n",
      "Epoch 55/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3151 - accuracy: 0.8657 - val_loss: 0.3085 - val_accuracy: 0.8686\n",
      "Epoch 56/100\n",
      "4250/4250 [==============================] - 10s 2ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3086 - val_accuracy: 0.8686\n",
      "Epoch 57/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3151 - accuracy: 0.8658 - val_loss: 0.3087 - val_accuracy: 0.8685\n",
      "Epoch 58/100\n",
      "4250/4250 [==============================] - 21s 5ms/step - loss: 0.3151 - accuracy: 0.8659 - val_loss: 0.3087 - val_accuracy: 0.8686\n",
      "Epoch 59/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3088 - val_accuracy: 0.8685\n",
      "Epoch 60/100\n",
      "4250/4250 [==============================] - 11s 2ms/step - loss: 0.3151 - accuracy: 0.8658 - val_loss: 0.3089 - val_accuracy: 0.8688\n",
      "Epoch 61/100\n",
      "4250/4250 [==============================] - 20s 5ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3085 - val_accuracy: 0.8687\n",
      "Epoch 62/100\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3091 - val_accuracy: 0.8688\n",
      "Epoch 63/100\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3151 - accuracy: 0.8657 - val_loss: 0.3089 - val_accuracy: 0.8689\n",
      "Epoch 64/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3086 - val_accuracy: 0.8688\n",
      "Epoch 65/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3150 - accuracy: 0.8661 - val_loss: 0.3092 - val_accuracy: 0.8685\n",
      "Epoch 66/100\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3151 - accuracy: 0.8657 - val_loss: 0.3085 - val_accuracy: 0.8685\n",
      "Epoch 67/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3150 - accuracy: 0.8656 - val_loss: 0.3090 - val_accuracy: 0.8685\n",
      "Epoch 68/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3086 - val_accuracy: 0.8689\n",
      "Epoch 69/100\n",
      "4250/4250 [==============================] - 19s 4ms/step - loss: 0.3150 - accuracy: 0.8657 - val_loss: 0.3087 - val_accuracy: 0.8683\n",
      "Epoch 70/100\n",
      "4250/4250 [==============================] - 20s 5ms/step - loss: 0.3150 - accuracy: 0.8658 - val_loss: 0.3085 - val_accuracy: 0.8688\n",
      "Epoch 71/100\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3150 - accuracy: 0.8657 - val_loss: 0.3088 - val_accuracy: 0.8689\n",
      "Epoch 72/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3150 - accuracy: 0.8657 - val_loss: 0.3087 - val_accuracy: 0.8690\n",
      "Epoch 73/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3151 - accuracy: 0.8657 - val_loss: 0.3089 - val_accuracy: 0.8682\n",
      "Epoch 74/100\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3086 - val_accuracy: 0.8689\n",
      "Epoch 75/100\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3087 - val_accuracy: 0.8686\n",
      "Epoch 76/100\n",
      "4250/4250 [==============================] - 18s 4ms/step - loss: 0.3150 - accuracy: 0.8661 - val_loss: 0.3089 - val_accuracy: 0.8688\n",
      "Epoch 77/100\n",
      "4250/4250 [==============================] - 20s 5ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3086 - val_accuracy: 0.8687\n",
      "Epoch 78/100\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3150 - accuracy: 0.8657 - val_loss: 0.3086 - val_accuracy: 0.8687\n",
      "Epoch 79/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3150 - accuracy: 0.8657 - val_loss: 0.3090 - val_accuracy: 0.8687\n",
      "Epoch 80/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3087 - val_accuracy: 0.8688\n",
      "Epoch 81/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3089 - val_accuracy: 0.8686\n",
      "Epoch 82/100\n",
      "4250/4250 [==============================] - 10s 2ms/step - loss: 0.3150 - accuracy: 0.8658 - val_loss: 0.3094 - val_accuracy: 0.8685\n",
      "Epoch 83/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3150 - accuracy: 0.8658 - val_loss: 0.3085 - val_accuracy: 0.8689\n",
      "Epoch 84/100\n",
      "4250/4250 [==============================] - 18s 4ms/step - loss: 0.3149 - accuracy: 0.8659 - val_loss: 0.3092 - val_accuracy: 0.8686\n",
      "Epoch 85/100\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3089 - val_accuracy: 0.8686\n",
      "Epoch 86/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3149 - accuracy: 0.8658 - val_loss: 0.3088 - val_accuracy: 0.8686\n",
      "Epoch 87/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3089 - val_accuracy: 0.8686\n",
      "Epoch 88/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.3090 - val_accuracy: 0.8685\n",
      "Epoch 89/100\n",
      "4250/4250 [==============================] - 11s 2ms/step - loss: 0.3149 - accuracy: 0.8657 - val_loss: 0.3089 - val_accuracy: 0.8687\n",
      "Epoch 90/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3094 - val_accuracy: 0.8685\n",
      "Epoch 91/100\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3149 - accuracy: 0.8656 - val_loss: 0.3094 - val_accuracy: 0.8687\n",
      "Epoch 92/100\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3149 - accuracy: 0.8659 - val_loss: 0.3087 - val_accuracy: 0.8690\n",
      "Epoch 93/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3149 - accuracy: 0.8660 - val_loss: 0.3087 - val_accuracy: 0.8686\n",
      "Epoch 94/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3148 - accuracy: 0.8658 - val_loss: 0.3086 - val_accuracy: 0.8688\n",
      "Epoch 95/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3150 - accuracy: 0.8660 - val_loss: 0.3087 - val_accuracy: 0.8687\n",
      "Epoch 96/100\n",
      "4250/4250 [==============================] - 15s 3ms/step - loss: 0.3149 - accuracy: 0.8656 - val_loss: 0.3087 - val_accuracy: 0.8683\n",
      "Epoch 97/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3150 - accuracy: 0.8658 - val_loss: 0.3087 - val_accuracy: 0.8692\n",
      "Epoch 98/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3149 - accuracy: 0.8661 - val_loss: 0.3089 - val_accuracy: 0.8687\n",
      "Epoch 99/100\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3149 - accuracy: 0.8658 - val_loss: 0.3086 - val_accuracy: 0.8686\n",
      "Epoch 100/100\n",
      "4250/4250 [==============================] - 15s 3ms/step - loss: 0.3149 - accuracy: 0.8659 - val_loss: 0.3086 - val_accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "'''Compiling ANN'''\n",
    "ann = keras_model(8)\n",
    "\n",
    "ann.compile(optimizer=\"Adam\",\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "'''Fitting ANN'''\n",
    "history = ann.fit(X_train, y_train, validation_split=0.33, batch_size=32,epochs = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8653421633554084"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Predicting and Evaluating Model'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred[y_pred <= 0.5] = 0.\n",
    "y_pred[y_pred > 0.5] = 1.\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Visualizing Accuracy and Loss'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "'''summarize history for accuracy'''\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''summarize history for loss'''\n",
    "# loss - elbow shaped means model have achieved maximum accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD binary_crossentropy 0.01 32 50\n",
      "Epoch 1/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3714 - accuracy: 0.8575 - val_loss: 0.3279 - val_accuracy: 0.8632\n",
      "Epoch 2/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3313 - accuracy: 0.8595 - val_loss: 0.3197 - val_accuracy: 0.8632\n",
      "Epoch 3/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3260 - accuracy: 0.8599 - val_loss: 0.3162 - val_accuracy: 0.8649\n",
      "Epoch 4/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3235 - accuracy: 0.8618 - val_loss: 0.3146 - val_accuracy: 0.8657\n",
      "Epoch 5/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3219 - accuracy: 0.8629 - val_loss: 0.3135 - val_accuracy: 0.8667\n",
      "Epoch 6/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3209 - accuracy: 0.8632 - val_loss: 0.3127 - val_accuracy: 0.8667\n",
      "Epoch 7/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3201 - accuracy: 0.8634 - val_loss: 0.3125 - val_accuracy: 0.8666\n",
      "Epoch 8/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3195 - accuracy: 0.8635 - val_loss: 0.3114 - val_accuracy: 0.8672\n",
      "Epoch 9/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3190 - accuracy: 0.8637 - val_loss: 0.3110 - val_accuracy: 0.8675\n",
      "Epoch 10/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3187 - accuracy: 0.8638 - val_loss: 0.3109 - val_accuracy: 0.8678\n",
      "Epoch 11/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3185 - accuracy: 0.8640 - val_loss: 0.3107 - val_accuracy: 0.8677\n",
      "Epoch 12/50\n",
      "4250/4250 [==============================] - 15s 3ms/step - loss: 0.3182 - accuracy: 0.8637 - val_loss: 0.3108 - val_accuracy: 0.8673\n",
      "Epoch 13/50\n",
      "4250/4250 [==============================] - 18s 4ms/step - loss: 0.3182 - accuracy: 0.8643 - val_loss: 0.3103 - val_accuracy: 0.8680\n",
      "Epoch 14/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3181 - accuracy: 0.8640 - val_loss: 0.3103 - val_accuracy: 0.8679\n",
      "Epoch 15/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3179 - accuracy: 0.8645 - val_loss: 0.3102 - val_accuracy: 0.8680\n",
      "Epoch 16/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3178 - accuracy: 0.8642 - val_loss: 0.3101 - val_accuracy: 0.8680\n",
      "Epoch 17/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3177 - accuracy: 0.8644 - val_loss: 0.3101 - val_accuracy: 0.8682\n",
      "Epoch 18/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3176 - accuracy: 0.8648 - val_loss: 0.3101 - val_accuracy: 0.8681\n",
      "Epoch 19/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3176 - accuracy: 0.8649 - val_loss: 0.3100 - val_accuracy: 0.8681\n",
      "Epoch 20/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3174 - accuracy: 0.8646 - val_loss: 0.3101 - val_accuracy: 0.8681\n",
      "Epoch 21/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3173 - accuracy: 0.8650 - val_loss: 0.3096 - val_accuracy: 0.8685\n",
      "Epoch 22/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3172 - accuracy: 0.8651 - val_loss: 0.3095 - val_accuracy: 0.8686\n",
      "Epoch 23/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3172 - accuracy: 0.8648 - val_loss: 0.3094 - val_accuracy: 0.8686\n",
      "Epoch 24/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3172 - accuracy: 0.8648 - val_loss: 0.3095 - val_accuracy: 0.8686\n",
      "Epoch 25/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3171 - accuracy: 0.8649 - val_loss: 0.3094 - val_accuracy: 0.8686\n",
      "Epoch 26/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3170 - accuracy: 0.8652 - val_loss: 0.3095 - val_accuracy: 0.8682\n",
      "Epoch 27/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3169 - accuracy: 0.8650 - val_loss: 0.3096 - val_accuracy: 0.8683\n",
      "Epoch 28/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3168 - accuracy: 0.8653 - val_loss: 0.3096 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "4250/4250 [==============================] - 22s 5ms/step - loss: 0.3168 - accuracy: 0.8650 - val_loss: 0.3093 - val_accuracy: 0.8682\n",
      "Epoch 30/50\n",
      "4250/4250 [==============================] - 24s 6ms/step - loss: 0.3167 - accuracy: 0.8651 - val_loss: 0.3092 - val_accuracy: 0.8682\n",
      "Epoch 31/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3166 - accuracy: 0.8649 - val_loss: 0.3091 - val_accuracy: 0.8685\n",
      "Epoch 32/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3166 - accuracy: 0.8655 - val_loss: 0.3094 - val_accuracy: 0.8681\n",
      "Epoch 33/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3165 - accuracy: 0.8654 - val_loss: 0.3090 - val_accuracy: 0.8687\n",
      "Epoch 34/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3165 - accuracy: 0.8655 - val_loss: 0.3090 - val_accuracy: 0.8687\n",
      "Epoch 35/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3164 - accuracy: 0.8653 - val_loss: 0.3102 - val_accuracy: 0.8675\n",
      "Epoch 36/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3165 - accuracy: 0.8654 - val_loss: 0.3092 - val_accuracy: 0.8685\n",
      "Epoch 37/50\n",
      "4250/4250 [==============================] - 10s 2ms/step - loss: 0.3164 - accuracy: 0.8657 - val_loss: 0.3088 - val_accuracy: 0.8685\n",
      "Epoch 38/50\n",
      "4250/4250 [==============================] - 10s 2ms/step - loss: 0.3163 - accuracy: 0.8652 - val_loss: 0.3088 - val_accuracy: 0.8686\n",
      "Epoch 39/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3163 - accuracy: 0.8654 - val_loss: 0.3088 - val_accuracy: 0.8683\n",
      "Epoch 40/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3162 - accuracy: 0.8653 - val_loss: 0.3089 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3162 - accuracy: 0.8657 - val_loss: 0.3086 - val_accuracy: 0.8686\n",
      "Epoch 42/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3162 - accuracy: 0.8654 - val_loss: 0.3087 - val_accuracy: 0.8689\n",
      "Epoch 43/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3161 - accuracy: 0.8653 - val_loss: 0.3095 - val_accuracy: 0.8685\n",
      "Epoch 44/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3161 - accuracy: 0.8654 - val_loss: 0.3086 - val_accuracy: 0.8686\n",
      "Epoch 45/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3161 - accuracy: 0.8655 - val_loss: 0.3087 - val_accuracy: 0.8685\n",
      "Epoch 46/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3160 - accuracy: 0.8654 - val_loss: 0.3085 - val_accuracy: 0.8687\n",
      "Epoch 47/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3160 - accuracy: 0.8655 - val_loss: 0.3087 - val_accuracy: 0.8685\n",
      "Epoch 48/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3160 - accuracy: 0.8655 - val_loss: 0.3087 - val_accuracy: 0.8682\n",
      "Epoch 49/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3160 - accuracy: 0.8657 - val_loss: 0.3086 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "4250/4250 [==============================] - 8s 2ms/step - loss: 0.3160 - accuracy: 0.8656 - val_loss: 0.3088 - val_accuracy: 0.8686\n",
      "ACCURACY: 0.8656575212866604\n",
      "SGD binary_crossentropy 0.01 64 50\n",
      "Epoch 1/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4411 - accuracy: 0.8384 - val_loss: 0.3736 - val_accuracy: 0.8630\n",
      "Epoch 2/50\n",
      "2125/2125 [==============================] - 9s 4ms/step - loss: 0.3595 - accuracy: 0.8595 - val_loss: 0.3368 - val_accuracy: 0.8644\n",
      "Epoch 3/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.3360 - accuracy: 0.8607 - val_loss: 0.3232 - val_accuracy: 0.8661\n",
      "Epoch 4/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3279 - accuracy: 0.8621 - val_loss: 0.3184 - val_accuracy: 0.8663\n",
      "Epoch 5/50\n",
      "2125/2125 [==============================] - 9s 4ms/step - loss: 0.3247 - accuracy: 0.8629 - val_loss: 0.3163 - val_accuracy: 0.8667\n",
      "Epoch 6/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.3230 - accuracy: 0.8633 - val_loss: 0.3153 - val_accuracy: 0.8666\n",
      "Epoch 7/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3220 - accuracy: 0.8636 - val_loss: 0.3143 - val_accuracy: 0.8667\n",
      "Epoch 8/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3213 - accuracy: 0.8638 - val_loss: 0.3136 - val_accuracy: 0.8669\n",
      "Epoch 9/50\n",
      "2125/2125 [==============================] - 5s 3ms/step - loss: 0.3207 - accuracy: 0.8639 - val_loss: 0.3132 - val_accuracy: 0.8669\n",
      "Epoch 10/50\n",
      "2125/2125 [==============================] - 5s 2ms/step - loss: 0.3203 - accuracy: 0.8639 - val_loss: 0.3129 - val_accuracy: 0.8670\n",
      "Epoch 11/50\n",
      "2125/2125 [==============================] - 5s 2ms/step - loss: 0.3199 - accuracy: 0.8641 - val_loss: 0.3125 - val_accuracy: 0.8673\n",
      "Epoch 12/50\n",
      "2125/2125 [==============================] - 5s 2ms/step - loss: 0.3197 - accuracy: 0.8644 - val_loss: 0.3122 - val_accuracy: 0.8673\n",
      "Epoch 13/50\n",
      "2125/2125 [==============================] - 5s 3ms/step - loss: 0.3194 - accuracy: 0.8642 - val_loss: 0.3121 - val_accuracy: 0.8672\n",
      "Epoch 14/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3191 - accuracy: 0.8646 - val_loss: 0.3118 - val_accuracy: 0.8672\n",
      "Epoch 15/50\n",
      "2125/2125 [==============================] - 5s 2ms/step - loss: 0.3189 - accuracy: 0.8646 - val_loss: 0.3116 - val_accuracy: 0.8675\n",
      "Epoch 16/50\n",
      "2125/2125 [==============================] - 5s 3ms/step - loss: 0.3187 - accuracy: 0.8648 - val_loss: 0.3114 - val_accuracy: 0.8675\n",
      "Epoch 17/50\n",
      "2125/2125 [==============================] - 5s 2ms/step - loss: 0.3185 - accuracy: 0.8645 - val_loss: 0.3113 - val_accuracy: 0.8676\n",
      "Epoch 18/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.3184 - accuracy: 0.8648 - val_loss: 0.3111 - val_accuracy: 0.8676\n",
      "Epoch 19/50\n",
      "2125/2125 [==============================] - 8s 4ms/step - loss: 0.3183 - accuracy: 0.8649 - val_loss: 0.3111 - val_accuracy: 0.8679\n",
      "Epoch 20/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3182 - accuracy: 0.8648 - val_loss: 0.3109 - val_accuracy: 0.8678\n",
      "Epoch 21/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3180 - accuracy: 0.8651 - val_loss: 0.3108 - val_accuracy: 0.8679\n",
      "Epoch 22/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3179 - accuracy: 0.8649 - val_loss: 0.3107 - val_accuracy: 0.8680\n",
      "Epoch 23/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3179 - accuracy: 0.8649 - val_loss: 0.3108 - val_accuracy: 0.8679\n",
      "Epoch 24/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3178 - accuracy: 0.8650 - val_loss: 0.3105 - val_accuracy: 0.8679\n",
      "Epoch 25/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3177 - accuracy: 0.8649 - val_loss: 0.3107 - val_accuracy: 0.8676\n",
      "Epoch 26/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3177 - accuracy: 0.8652 - val_loss: 0.3104 - val_accuracy: 0.8681\n",
      "Epoch 27/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3176 - accuracy: 0.8651 - val_loss: 0.3106 - val_accuracy: 0.8679\n",
      "Epoch 28/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3175 - accuracy: 0.8651 - val_loss: 0.3104 - val_accuracy: 0.8679\n",
      "Epoch 29/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3175 - accuracy: 0.8651 - val_loss: 0.3103 - val_accuracy: 0.8682\n",
      "Epoch 30/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3174 - accuracy: 0.8650 - val_loss: 0.3105 - val_accuracy: 0.8675\n",
      "Epoch 31/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3174 - accuracy: 0.8652 - val_loss: 0.3103 - val_accuracy: 0.8682\n",
      "Epoch 32/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3173 - accuracy: 0.8650 - val_loss: 0.3102 - val_accuracy: 0.8683\n",
      "Epoch 33/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3173 - accuracy: 0.8652 - val_loss: 0.3102 - val_accuracy: 0.8679\n",
      "Epoch 34/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3173 - accuracy: 0.8651 - val_loss: 0.3102 - val_accuracy: 0.8681\n",
      "Epoch 35/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3172 - accuracy: 0.8651 - val_loss: 0.3101 - val_accuracy: 0.8683\n",
      "Epoch 36/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3172 - accuracy: 0.8651 - val_loss: 0.3102 - val_accuracy: 0.8677\n",
      "Epoch 37/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3172 - accuracy: 0.8650 - val_loss: 0.3100 - val_accuracy: 0.8683\n",
      "Epoch 38/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3171 - accuracy: 0.8651 - val_loss: 0.3100 - val_accuracy: 0.8682\n",
      "Epoch 39/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3171 - accuracy: 0.8651 - val_loss: 0.3099 - val_accuracy: 0.8683\n",
      "Epoch 40/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3171 - accuracy: 0.8652 - val_loss: 0.3101 - val_accuracy: 0.8678\n",
      "Epoch 41/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3171 - accuracy: 0.8650 - val_loss: 0.3099 - val_accuracy: 0.8683\n",
      "Epoch 42/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3170 - accuracy: 0.8650 - val_loss: 0.3099 - val_accuracy: 0.8680\n",
      "Epoch 43/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3170 - accuracy: 0.8651 - val_loss: 0.3099 - val_accuracy: 0.8683\n",
      "Epoch 44/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3170 - accuracy: 0.8651 - val_loss: 0.3099 - val_accuracy: 0.8678\n",
      "Epoch 45/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3169 - accuracy: 0.8651 - val_loss: 0.3100 - val_accuracy: 0.8675\n",
      "Epoch 46/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3169 - accuracy: 0.8653 - val_loss: 0.3099 - val_accuracy: 0.8678\n",
      "Epoch 47/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3169 - accuracy: 0.8652 - val_loss: 0.3098 - val_accuracy: 0.8680\n",
      "Epoch 48/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3169 - accuracy: 0.8652 - val_loss: 0.3097 - val_accuracy: 0.8683\n",
      "Epoch 49/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3169 - accuracy: 0.8650 - val_loss: 0.3097 - val_accuracy: 0.8683\n",
      "Epoch 50/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3169 - accuracy: 0.8651 - val_loss: 0.3098 - val_accuracy: 0.8678\n",
      "ACCURACY: 0.8653224534847052\n",
      "SGD binary_crossentropy 0.01 128 50\n",
      "Epoch 1/50\n",
      "1063/1063 [==============================] - 4s 3ms/step - loss: 0.3911 - accuracy: 0.8596 - val_loss: 0.3374 - val_accuracy: 0.8632\n",
      "Epoch 2/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3384 - accuracy: 0.8596 - val_loss: 0.3279 - val_accuracy: 0.8631\n",
      "Epoch 3/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3328 - accuracy: 0.8596 - val_loss: 0.3244 - val_accuracy: 0.8631\n",
      "Epoch 4/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3301 - accuracy: 0.8596 - val_loss: 0.3222 - val_accuracy: 0.8632\n",
      "Epoch 5/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3285 - accuracy: 0.8596 - val_loss: 0.3208 - val_accuracy: 0.8632\n",
      "Epoch 6/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3272 - accuracy: 0.8596 - val_loss: 0.3197 - val_accuracy: 0.8632\n",
      "Epoch 7/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3262 - accuracy: 0.8599 - val_loss: 0.3187 - val_accuracy: 0.8633\n",
      "Epoch 8/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3254 - accuracy: 0.8599 - val_loss: 0.3180 - val_accuracy: 0.8633\n",
      "Epoch 9/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3247 - accuracy: 0.8601 - val_loss: 0.3173 - val_accuracy: 0.8636\n",
      "Epoch 10/50\n",
      "1063/1063 [==============================] - 4s 4ms/step - loss: 0.3241 - accuracy: 0.8602 - val_loss: 0.3167 - val_accuracy: 0.8637\n",
      "Epoch 11/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3236 - accuracy: 0.8603 - val_loss: 0.3162 - val_accuracy: 0.8638\n",
      "Epoch 12/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3231 - accuracy: 0.8607 - val_loss: 0.3157 - val_accuracy: 0.8638\n",
      "Epoch 13/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3226 - accuracy: 0.8607 - val_loss: 0.3152 - val_accuracy: 0.8640\n",
      "Epoch 14/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3222 - accuracy: 0.8610 - val_loss: 0.3147 - val_accuracy: 0.8641\n",
      "Epoch 15/50\n",
      "1063/1063 [==============================] - 4s 3ms/step - loss: 0.3218 - accuracy: 0.8613 - val_loss: 0.3143 - val_accuracy: 0.8642\n",
      "Epoch 16/50\n",
      "1063/1063 [==============================] - 4s 3ms/step - loss: 0.3214 - accuracy: 0.8614 - val_loss: 0.3140 - val_accuracy: 0.8644\n",
      "Epoch 17/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3210 - accuracy: 0.8616 - val_loss: 0.3135 - val_accuracy: 0.8644\n",
      "Epoch 18/50\n",
      "1063/1063 [==============================] - 4s 4ms/step - loss: 0.3208 - accuracy: 0.8614 - val_loss: 0.3133 - val_accuracy: 0.8650\n",
      "Epoch 19/50\n",
      "1063/1063 [==============================] - 4s 3ms/step - loss: 0.3205 - accuracy: 0.8617 - val_loss: 0.3129 - val_accuracy: 0.8649\n",
      "Epoch 20/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3203 - accuracy: 0.8619 - val_loss: 0.3128 - val_accuracy: 0.8652\n",
      "Epoch 21/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3200 - accuracy: 0.8621 - val_loss: 0.3124 - val_accuracy: 0.8650\n",
      "Epoch 22/50\n",
      "1063/1063 [==============================] - 4s 3ms/step - loss: 0.3198 - accuracy: 0.8622 - val_loss: 0.3122 - val_accuracy: 0.8651\n",
      "Epoch 23/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3196 - accuracy: 0.8623 - val_loss: 0.3121 - val_accuracy: 0.8655\n",
      "Epoch 24/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3194 - accuracy: 0.8624 - val_loss: 0.3118 - val_accuracy: 0.8653\n",
      "Epoch 25/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3192 - accuracy: 0.8624 - val_loss: 0.3116 - val_accuracy: 0.8658\n",
      "Epoch 26/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3191 - accuracy: 0.8625 - val_loss: 0.3115 - val_accuracy: 0.8657\n",
      "Epoch 27/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3189 - accuracy: 0.8627 - val_loss: 0.3113 - val_accuracy: 0.8656\n",
      "Epoch 28/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3188 - accuracy: 0.8626 - val_loss: 0.3111 - val_accuracy: 0.8656\n",
      "Epoch 29/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3187 - accuracy: 0.8628 - val_loss: 0.3110 - val_accuracy: 0.8659\n",
      "Epoch 30/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3185 - accuracy: 0.8631 - val_loss: 0.3108 - val_accuracy: 0.8659\n",
      "Epoch 31/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3184 - accuracy: 0.8631 - val_loss: 0.3107 - val_accuracy: 0.8662\n",
      "Epoch 32/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3183 - accuracy: 0.8633 - val_loss: 0.3107 - val_accuracy: 0.8662\n",
      "Epoch 33/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3182 - accuracy: 0.8633 - val_loss: 0.3106 - val_accuracy: 0.8660\n",
      "Epoch 34/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3181 - accuracy: 0.8635 - val_loss: 0.3103 - val_accuracy: 0.8664\n",
      "Epoch 35/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3180 - accuracy: 0.8635 - val_loss: 0.3103 - val_accuracy: 0.8662\n",
      "Epoch 36/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3179 - accuracy: 0.8637 - val_loss: 0.3104 - val_accuracy: 0.8664\n",
      "Epoch 37/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3178 - accuracy: 0.8639 - val_loss: 0.3100 - val_accuracy: 0.8664\n",
      "Epoch 38/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3177 - accuracy: 0.8640 - val_loss: 0.3100 - val_accuracy: 0.8666\n",
      "Epoch 39/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3176 - accuracy: 0.8638 - val_loss: 0.3098 - val_accuracy: 0.8668\n",
      "Epoch 40/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3176 - accuracy: 0.8640 - val_loss: 0.3097 - val_accuracy: 0.8670\n",
      "Epoch 41/50\n",
      "1063/1063 [==============================] - 4s 4ms/step - loss: 0.3175 - accuracy: 0.8643 - val_loss: 0.3097 - val_accuracy: 0.8668\n",
      "Epoch 42/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3174 - accuracy: 0.8643 - val_loss: 0.3096 - val_accuracy: 0.8672\n",
      "Epoch 43/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3173 - accuracy: 0.8644 - val_loss: 0.3096 - val_accuracy: 0.8672\n",
      "Epoch 44/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3173 - accuracy: 0.8643 - val_loss: 0.3095 - val_accuracy: 0.8676\n",
      "Epoch 45/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3172 - accuracy: 0.8647 - val_loss: 0.3093 - val_accuracy: 0.8676\n",
      "Epoch 46/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3172 - accuracy: 0.8647 - val_loss: 0.3094 - val_accuracy: 0.8678\n",
      "Epoch 47/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3171 - accuracy: 0.8647 - val_loss: 0.3092 - val_accuracy: 0.8677\n",
      "Epoch 48/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3171 - accuracy: 0.8646 - val_loss: 0.3091 - val_accuracy: 0.8677\n",
      "Epoch 49/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3170 - accuracy: 0.8648 - val_loss: 0.3091 - val_accuracy: 0.8680\n",
      "Epoch 50/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.3170 - accuracy: 0.8647 - val_loss: 0.3092 - val_accuracy: 0.8682\n",
      "ACCURACY: 0.8652041942604857\n",
      "SGD binary_crossentropy 0.001 32 50\n",
      "Epoch 1/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.4745 - accuracy: 0.8420 - val_loss: 0.3850 - val_accuracy: 0.8632\n",
      "Epoch 2/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3727 - accuracy: 0.8596 - val_loss: 0.3534 - val_accuracy: 0.8632\n",
      "Epoch 3/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3545 - accuracy: 0.8595 - val_loss: 0.3428 - val_accuracy: 0.8630\n",
      "Epoch 4/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3468 - accuracy: 0.8595 - val_loss: 0.3372 - val_accuracy: 0.8632\n",
      "Epoch 5/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3423 - accuracy: 0.8596 - val_loss: 0.3335 - val_accuracy: 0.8629\n",
      "Epoch 6/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3391 - accuracy: 0.8598 - val_loss: 0.3308 - val_accuracy: 0.8627\n",
      "Epoch 7/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3368 - accuracy: 0.8598 - val_loss: 0.3287 - val_accuracy: 0.8628\n",
      "Epoch 8/50\n",
      "4250/4250 [==============================] - 26s 6ms/step - loss: 0.3349 - accuracy: 0.8599 - val_loss: 0.3270 - val_accuracy: 0.8629\n",
      "Epoch 9/50\n",
      "4250/4250 [==============================] - 24s 6ms/step - loss: 0.3333 - accuracy: 0.8600 - val_loss: 0.3255 - val_accuracy: 0.8631\n",
      "Epoch 10/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3320 - accuracy: 0.8602 - val_loss: 0.3242 - val_accuracy: 0.8633\n",
      "Epoch 11/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3308 - accuracy: 0.8602 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 12/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3298 - accuracy: 0.8604 - val_loss: 0.3222 - val_accuracy: 0.8636\n",
      "Epoch 13/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3289 - accuracy: 0.8606 - val_loss: 0.3214 - val_accuracy: 0.8638\n",
      "Epoch 14/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3281 - accuracy: 0.8607 - val_loss: 0.3207 - val_accuracy: 0.8637\n",
      "Epoch 15/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3275 - accuracy: 0.8608 - val_loss: 0.3200 - val_accuracy: 0.8639\n",
      "Epoch 16/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3269 - accuracy: 0.8611 - val_loss: 0.3194 - val_accuracy: 0.8641\n",
      "Epoch 17/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3263 - accuracy: 0.8612 - val_loss: 0.3189 - val_accuracy: 0.8643\n",
      "Epoch 18/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3258 - accuracy: 0.8613 - val_loss: 0.3184 - val_accuracy: 0.8645\n",
      "Epoch 19/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3254 - accuracy: 0.8613 - val_loss: 0.3179 - val_accuracy: 0.8646\n",
      "Epoch 20/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3250 - accuracy: 0.8614 - val_loss: 0.3175 - val_accuracy: 0.8649\n",
      "Epoch 21/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3246 - accuracy: 0.8616 - val_loss: 0.3171 - val_accuracy: 0.8650\n",
      "Epoch 22/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3242 - accuracy: 0.8617 - val_loss: 0.3168 - val_accuracy: 0.8649\n",
      "Epoch 23/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3239 - accuracy: 0.8619 - val_loss: 0.3164 - val_accuracy: 0.8649\n",
      "Epoch 24/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3236 - accuracy: 0.8620 - val_loss: 0.3161 - val_accuracy: 0.8650\n",
      "Epoch 25/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3233 - accuracy: 0.8621 - val_loss: 0.3158 - val_accuracy: 0.8651\n",
      "Epoch 26/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3230 - accuracy: 0.8622 - val_loss: 0.3155 - val_accuracy: 0.8653\n",
      "Epoch 27/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3227 - accuracy: 0.8625 - val_loss: 0.3152 - val_accuracy: 0.8654\n",
      "Epoch 28/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3225 - accuracy: 0.8626 - val_loss: 0.3150 - val_accuracy: 0.8655\n",
      "Epoch 29/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3223 - accuracy: 0.8627 - val_loss: 0.3148 - val_accuracy: 0.8657\n",
      "Epoch 30/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3220 - accuracy: 0.8629 - val_loss: 0.3145 - val_accuracy: 0.8658\n",
      "Epoch 31/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3218 - accuracy: 0.8630 - val_loss: 0.3143 - val_accuracy: 0.8657\n",
      "Epoch 32/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3216 - accuracy: 0.8630 - val_loss: 0.3141 - val_accuracy: 0.8658\n",
      "Epoch 33/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3215 - accuracy: 0.8631 - val_loss: 0.3139 - val_accuracy: 0.8659\n",
      "Epoch 34/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3213 - accuracy: 0.8631 - val_loss: 0.3138 - val_accuracy: 0.8659\n",
      "Epoch 35/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3211 - accuracy: 0.8630 - val_loss: 0.3136 - val_accuracy: 0.8660\n",
      "Epoch 36/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3210 - accuracy: 0.8631 - val_loss: 0.3134 - val_accuracy: 0.8660\n",
      "Epoch 37/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3208 - accuracy: 0.8632 - val_loss: 0.3132 - val_accuracy: 0.8662\n",
      "Epoch 38/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3207 - accuracy: 0.8632 - val_loss: 0.3131 - val_accuracy: 0.8662\n",
      "Epoch 39/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3205 - accuracy: 0.8632 - val_loss: 0.3130 - val_accuracy: 0.8662\n",
      "Epoch 40/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3204 - accuracy: 0.8635 - val_loss: 0.3128 - val_accuracy: 0.8662\n",
      "Epoch 41/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3203 - accuracy: 0.8635 - val_loss: 0.3128 - val_accuracy: 0.8663\n",
      "Epoch 42/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3202 - accuracy: 0.8634 - val_loss: 0.3126 - val_accuracy: 0.8664\n",
      "Epoch 43/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3201 - accuracy: 0.8635 - val_loss: 0.3125 - val_accuracy: 0.8662\n",
      "Epoch 44/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3199 - accuracy: 0.8635 - val_loss: 0.3123 - val_accuracy: 0.8661\n",
      "Epoch 45/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.3198 - accuracy: 0.8636 - val_loss: 0.3123 - val_accuracy: 0.8662\n",
      "Epoch 46/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3197 - accuracy: 0.8636 - val_loss: 0.3121 - val_accuracy: 0.8661\n",
      "Epoch 47/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3196 - accuracy: 0.8638 - val_loss: 0.3120 - val_accuracy: 0.8662\n",
      "Epoch 48/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3195 - accuracy: 0.8637 - val_loss: 0.3120 - val_accuracy: 0.8662\n",
      "Epoch 49/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3194 - accuracy: 0.8638 - val_loss: 0.3119 - val_accuracy: 0.8662\n",
      "Epoch 50/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.3194 - accuracy: 0.8637 - val_loss: 0.3118 - val_accuracy: 0.8662\n",
      "ACCURACY: 0.8646523178807947\n",
      "SGD binary_crossentropy 0.001 64 50\n",
      "Epoch 1/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.5197 - accuracy: 0.7971 - val_loss: 0.4193 - val_accuracy: 0.8627\n",
      "Epoch 2/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3998 - accuracy: 0.8595 - val_loss: 0.3785 - val_accuracy: 0.8632\n",
      "Epoch 3/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3760 - accuracy: 0.8596 - val_loss: 0.3630 - val_accuracy: 0.8632\n",
      "Epoch 4/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3642 - accuracy: 0.8596 - val_loss: 0.3537 - val_accuracy: 0.8632\n",
      "Epoch 5/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3566 - accuracy: 0.8596 - val_loss: 0.3474 - val_accuracy: 0.8633\n",
      "Epoch 6/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3514 - accuracy: 0.8597 - val_loss: 0.3430 - val_accuracy: 0.8634\n",
      "Epoch 7/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3476 - accuracy: 0.8599 - val_loss: 0.3397 - val_accuracy: 0.8634\n",
      "Epoch 8/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3448 - accuracy: 0.8597 - val_loss: 0.3372 - val_accuracy: 0.8631\n",
      "Epoch 9/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3426 - accuracy: 0.8598 - val_loss: 0.3352 - val_accuracy: 0.8633\n",
      "Epoch 10/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3408 - accuracy: 0.8597 - val_loss: 0.3335 - val_accuracy: 0.8632\n",
      "Epoch 11/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3393 - accuracy: 0.8596 - val_loss: 0.3321 - val_accuracy: 0.8632\n",
      "Epoch 12/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3380 - accuracy: 0.8595 - val_loss: 0.3309 - val_accuracy: 0.8632\n",
      "Epoch 13/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3369 - accuracy: 0.8594 - val_loss: 0.3298 - val_accuracy: 0.8632\n",
      "Epoch 14/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3359 - accuracy: 0.8594 - val_loss: 0.3289 - val_accuracy: 0.8632\n",
      "Epoch 15/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3351 - accuracy: 0.8594 - val_loss: 0.3280 - val_accuracy: 0.8632\n",
      "Epoch 16/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3343 - accuracy: 0.8594 - val_loss: 0.3273 - val_accuracy: 0.8630\n",
      "Epoch 17/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3336 - accuracy: 0.8594 - val_loss: 0.3266 - val_accuracy: 0.8629\n",
      "Epoch 18/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3330 - accuracy: 0.8593 - val_loss: 0.3260 - val_accuracy: 0.8629\n",
      "Epoch 19/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3324 - accuracy: 0.8593 - val_loss: 0.3254 - val_accuracy: 0.8628\n",
      "Epoch 20/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3318 - accuracy: 0.8594 - val_loss: 0.3248 - val_accuracy: 0.8629\n",
      "Epoch 21/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3313 - accuracy: 0.8594 - val_loss: 0.3242 - val_accuracy: 0.8629\n",
      "Epoch 22/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3308 - accuracy: 0.8594 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 23/50\n",
      "2125/2125 [==============================] - 4s 2ms/step - loss: 0.3303 - accuracy: 0.8595 - val_loss: 0.3233 - val_accuracy: 0.8630\n",
      "Epoch 24/50\n",
      "2125/2125 [==============================] - 4s 2ms/step - loss: 0.3299 - accuracy: 0.8595 - val_loss: 0.3228 - val_accuracy: 0.8630\n",
      "Epoch 25/50\n",
      "2125/2125 [==============================] - 4s 2ms/step - loss: 0.3295 - accuracy: 0.8594 - val_loss: 0.3224 - val_accuracy: 0.8631\n",
      "Epoch 26/50\n",
      "2125/2125 [==============================] - 4s 2ms/step - loss: 0.3291 - accuracy: 0.8595 - val_loss: 0.3221 - val_accuracy: 0.8632\n",
      "Epoch 27/50\n",
      "2125/2125 [==============================] - 495s 233ms/step - loss: 0.3287 - accuracy: 0.8595 - val_loss: 0.3217 - val_accuracy: 0.8631\n",
      "Epoch 28/50\n",
      "2125/2125 [==============================] - 14s 6ms/step - loss: 0.3284 - accuracy: 0.8596 - val_loss: 0.3214 - val_accuracy: 0.8631\n",
      "Epoch 29/50\n",
      "2125/2125 [==============================] - 20s 10ms/step - loss: 0.3280 - accuracy: 0.8596 - val_loss: 0.3210 - val_accuracy: 0.8631\n",
      "Epoch 30/50\n",
      "2125/2125 [==============================] - 564s 266ms/step - loss: 0.3277 - accuracy: 0.8596 - val_loss: 0.3207 - val_accuracy: 0.8633\n",
      "Epoch 31/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3274 - accuracy: 0.8597 - val_loss: 0.3204 - val_accuracy: 0.8632\n",
      "Epoch 32/50\n",
      "2125/2125 [==============================] - 15s 7ms/step - loss: 0.3271 - accuracy: 0.8597 - val_loss: 0.3201 - val_accuracy: 0.8633\n",
      "Epoch 33/50\n",
      "2125/2125 [==============================] - 19s 9ms/step - loss: 0.3269 - accuracy: 0.8598 - val_loss: 0.3199 - val_accuracy: 0.8634\n",
      "Epoch 34/50\n",
      "2125/2125 [==============================] - 912s 430ms/step - loss: 0.3266 - accuracy: 0.8599 - val_loss: 0.3197 - val_accuracy: 0.8634\n",
      "Epoch 35/50\n",
      "2125/2125 [==============================] - 11s 5ms/step - loss: 0.3264 - accuracy: 0.8601 - val_loss: 0.3194 - val_accuracy: 0.8635\n",
      "Epoch 36/50\n",
      "2125/2125 [==============================] - 31s 15ms/step - loss: 0.3262 - accuracy: 0.8601 - val_loss: 0.3192 - val_accuracy: 0.8635\n",
      "Epoch 37/50\n",
      "2125/2125 [==============================] - 38s 18ms/step - loss: 0.3259 - accuracy: 0.8602 - val_loss: 0.3190 - val_accuracy: 0.8636\n",
      "Epoch 38/50\n",
      "2125/2125 [==============================] - 34s 16ms/step - loss: 0.3257 - accuracy: 0.8603 - val_loss: 0.3187 - val_accuracy: 0.8636\n",
      "Epoch 39/50\n",
      "2125/2125 [==============================] - 34s 16ms/step - loss: 0.3255 - accuracy: 0.8604 - val_loss: 0.3186 - val_accuracy: 0.8638\n",
      "Epoch 40/50\n",
      "2125/2125 [==============================] - 25s 12ms/step - loss: 0.3253 - accuracy: 0.8604 - val_loss: 0.3184 - val_accuracy: 0.8637\n",
      "Epoch 41/50\n",
      "2125/2125 [==============================] - 22s 10ms/step - loss: 0.3252 - accuracy: 0.8605 - val_loss: 0.3182 - val_accuracy: 0.8637\n",
      "Epoch 42/50\n",
      "2125/2125 [==============================] - 23s 11ms/step - loss: 0.3250 - accuracy: 0.8605 - val_loss: 0.3180 - val_accuracy: 0.8639\n",
      "Epoch 43/50\n",
      "2125/2125 [==============================] - 21s 10ms/step - loss: 0.3248 - accuracy: 0.8607 - val_loss: 0.3179 - val_accuracy: 0.8640\n",
      "Epoch 44/50\n",
      "2125/2125 [==============================] - 20s 9ms/step - loss: 0.3247 - accuracy: 0.8607 - val_loss: 0.3177 - val_accuracy: 0.8639\n",
      "Epoch 45/50\n",
      "2125/2125 [==============================] - 20s 9ms/step - loss: 0.3245 - accuracy: 0.8607 - val_loss: 0.3176 - val_accuracy: 0.8639\n",
      "Epoch 46/50\n",
      "2125/2125 [==============================] - 20s 9ms/step - loss: 0.3244 - accuracy: 0.8608 - val_loss: 0.3174 - val_accuracy: 0.8640\n",
      "Epoch 47/50\n",
      "2125/2125 [==============================] - 21s 10ms/step - loss: 0.3243 - accuracy: 0.8609 - val_loss: 0.3173 - val_accuracy: 0.8641\n",
      "Epoch 48/50\n",
      "2125/2125 [==============================] - 50s 24ms/step - loss: 0.3241 - accuracy: 0.8609 - val_loss: 0.3172 - val_accuracy: 0.8639\n",
      "Epoch 49/50\n",
      "2125/2125 [==============================] - 24s 11ms/step - loss: 0.3240 - accuracy: 0.8611 - val_loss: 0.3171 - val_accuracy: 0.8641\n",
      "Epoch 50/50\n",
      "2125/2125 [==============================] - 20s 9ms/step - loss: 0.3239 - accuracy: 0.8611 - val_loss: 0.3169 - val_accuracy: 0.8641\n",
      "ACCURACY: 0.8618338063702302\n",
      "SGD binary_crossentropy 0.001 128 50\n",
      "Epoch 1/50\n",
      "1063/1063 [==============================] - 11s 9ms/step - loss: 0.5915 - accuracy: 0.7351 - val_loss: 0.4826 - val_accuracy: 0.8604\n",
      "Epoch 2/50\n",
      "1063/1063 [==============================] - 8s 8ms/step - loss: 0.4469 - accuracy: 0.8588 - val_loss: 0.4143 - val_accuracy: 0.8632\n",
      "Epoch 3/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.4057 - accuracy: 0.8596 - val_loss: 0.3882 - val_accuracy: 0.8632\n",
      "Epoch 4/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3876 - accuracy: 0.8596 - val_loss: 0.3744 - val_accuracy: 0.8632\n",
      "Epoch 5/50\n",
      "1063/1063 [==============================] - 14s 13ms/step - loss: 0.3770 - accuracy: 0.8596 - val_loss: 0.3655 - val_accuracy: 0.8632\n",
      "Epoch 6/50\n",
      "1063/1063 [==============================] - 30s 28ms/step - loss: 0.3696 - accuracy: 0.8596 - val_loss: 0.3590 - val_accuracy: 0.8632\n",
      "Epoch 7/50\n",
      "1063/1063 [==============================] - 15s 14ms/step - loss: 0.3641 - accuracy: 0.8596 - val_loss: 0.3540 - val_accuracy: 0.8631\n",
      "Epoch 8/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3598 - accuracy: 0.8595 - val_loss: 0.3502 - val_accuracy: 0.8631\n",
      "Epoch 9/50\n",
      "1063/1063 [==============================] - 12s 11ms/step - loss: 0.3564 - accuracy: 0.8595 - val_loss: 0.3470 - val_accuracy: 0.8630\n",
      "Epoch 10/50\n",
      "1063/1063 [==============================] - 10s 9ms/step - loss: 0.3537 - accuracy: 0.8595 - val_loss: 0.3445 - val_accuracy: 0.8630\n",
      "Epoch 11/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3513 - accuracy: 0.8594 - val_loss: 0.3423 - val_accuracy: 0.8630\n",
      "Epoch 12/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3494 - accuracy: 0.8594 - val_loss: 0.3404 - val_accuracy: 0.8631\n",
      "Epoch 13/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3476 - accuracy: 0.8594 - val_loss: 0.3388 - val_accuracy: 0.8630\n",
      "Epoch 14/50\n",
      "1063/1063 [==============================] - 10s 9ms/step - loss: 0.3461 - accuracy: 0.8593 - val_loss: 0.3374 - val_accuracy: 0.8630\n",
      "Epoch 15/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3448 - accuracy: 0.8593 - val_loss: 0.3361 - val_accuracy: 0.8630\n",
      "Epoch 16/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3436 - accuracy: 0.8592 - val_loss: 0.3350 - val_accuracy: 0.8631\n",
      "Epoch 17/50\n",
      "1063/1063 [==============================] - 26s 25ms/step - loss: 0.3425 - accuracy: 0.8592 - val_loss: 0.3340 - val_accuracy: 0.8631\n",
      "Epoch 18/50\n",
      "1063/1063 [==============================] - 20s 19ms/step - loss: 0.3416 - accuracy: 0.8593 - val_loss: 0.3330 - val_accuracy: 0.8630\n",
      "Epoch 19/50\n",
      "1063/1063 [==============================] - 10s 9ms/step - loss: 0.3407 - accuracy: 0.8592 - val_loss: 0.3322 - val_accuracy: 0.8631\n",
      "Epoch 20/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3399 - accuracy: 0.8592 - val_loss: 0.3314 - val_accuracy: 0.8630\n",
      "Epoch 21/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3391 - accuracy: 0.8592 - val_loss: 0.3307 - val_accuracy: 0.8630\n",
      "Epoch 22/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3384 - accuracy: 0.8592 - val_loss: 0.3301 - val_accuracy: 0.8630\n",
      "Epoch 23/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3378 - accuracy: 0.8593 - val_loss: 0.3294 - val_accuracy: 0.8629\n",
      "Epoch 24/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3372 - accuracy: 0.8592 - val_loss: 0.3289 - val_accuracy: 0.8630\n",
      "Epoch 25/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3366 - accuracy: 0.8592 - val_loss: 0.3284 - val_accuracy: 0.8630\n",
      "Epoch 26/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3361 - accuracy: 0.8592 - val_loss: 0.3279 - val_accuracy: 0.8631\n",
      "Epoch 27/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3356 - accuracy: 0.8592 - val_loss: 0.3274 - val_accuracy: 0.8630\n",
      "Epoch 28/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3352 - accuracy: 0.8592 - val_loss: 0.3270 - val_accuracy: 0.8631\n",
      "Epoch 29/50\n",
      "1063/1063 [==============================] - 13s 12ms/step - loss: 0.3347 - accuracy: 0.8592 - val_loss: 0.3266 - val_accuracy: 0.8631\n",
      "Epoch 30/50\n",
      "1063/1063 [==============================] - 25s 23ms/step - loss: 0.3343 - accuracy: 0.8591 - val_loss: 0.3262 - val_accuracy: 0.8631\n",
      "Epoch 31/50\n",
      "1063/1063 [==============================] - 20s 19ms/step - loss: 0.3339 - accuracy: 0.8593 - val_loss: 0.3259 - val_accuracy: 0.8630\n",
      "Epoch 32/50\n",
      "1063/1063 [==============================] - 14s 13ms/step - loss: 0.3336 - accuracy: 0.8591 - val_loss: 0.3255 - val_accuracy: 0.8630\n",
      "Epoch 33/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3332 - accuracy: 0.8592 - val_loss: 0.3252 - val_accuracy: 0.8632\n",
      "Epoch 34/50\n",
      "1063/1063 [==============================] - 10s 9ms/step - loss: 0.3329 - accuracy: 0.8593 - val_loss: 0.3249 - val_accuracy: 0.8633\n",
      "Epoch 35/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3326 - accuracy: 0.8592 - val_loss: 0.3246 - val_accuracy: 0.8631\n",
      "Epoch 36/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3323 - accuracy: 0.8592 - val_loss: 0.3244 - val_accuracy: 0.8631\n",
      "Epoch 37/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3320 - accuracy: 0.8593 - val_loss: 0.3241 - val_accuracy: 0.8632\n",
      "Epoch 38/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3317 - accuracy: 0.8593 - val_loss: 0.3239 - val_accuracy: 0.8631\n",
      "Epoch 39/50\n",
      "1063/1063 [==============================] - 9s 9ms/step - loss: 0.3314 - accuracy: 0.8593 - val_loss: 0.3236 - val_accuracy: 0.8632\n",
      "Epoch 40/50\n",
      "1063/1063 [==============================] - 9s 8ms/step - loss: 0.3312 - accuracy: 0.8594 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 41/50\n",
      "1063/1063 [==============================] - 10s 10ms/step - loss: 0.3309 - accuracy: 0.8594 - val_loss: 0.3232 - val_accuracy: 0.8632\n",
      "Epoch 42/50\n",
      "1063/1063 [==============================] - 10s 10ms/step - loss: 0.3307 - accuracy: 0.8594 - val_loss: 0.3230 - val_accuracy: 0.8633\n",
      "Epoch 43/50\n",
      "1063/1063 [==============================] - 25s 23ms/step - loss: 0.3305 - accuracy: 0.8595 - val_loss: 0.3228 - val_accuracy: 0.8633\n",
      "Epoch 44/50\n",
      "1063/1063 [==============================] - 23s 22ms/step - loss: 0.3303 - accuracy: 0.8595 - val_loss: 0.3226 - val_accuracy: 0.8634\n",
      "Epoch 45/50\n",
      "1063/1063 [==============================] - 12s 11ms/step - loss: 0.3301 - accuracy: 0.8596 - val_loss: 0.3224 - val_accuracy: 0.8634\n",
      "Epoch 46/50\n",
      "1063/1063 [==============================] - 13s 12ms/step - loss: 0.3299 - accuracy: 0.8596 - val_loss: 0.3222 - val_accuracy: 0.8634\n",
      "Epoch 47/50\n",
      "1063/1063 [==============================] - 16s 15ms/step - loss: 0.3297 - accuracy: 0.8596 - val_loss: 0.3220 - val_accuracy: 0.8635\n",
      "Epoch 48/50\n",
      "1063/1063 [==============================] - 14s 13ms/step - loss: 0.3295 - accuracy: 0.8597 - val_loss: 0.3219 - val_accuracy: 0.8635\n",
      "Epoch 49/50\n",
      "1063/1063 [==============================] - 11s 10ms/step - loss: 0.3293 - accuracy: 0.8597 - val_loss: 0.3217 - val_accuracy: 0.8635\n",
      "Epoch 50/50\n",
      "1063/1063 [==============================] - 12s 11ms/step - loss: 0.3291 - accuracy: 0.8598 - val_loss: 0.3215 - val_accuracy: 0.8635\n",
      "ACCURACY: 0.8610059918006938\n",
      "SGD binary_crossentropy 0.0001 32 50\n",
      "Epoch 1/50\n",
      "4250/4250 [==============================] - 58s 13ms/step - loss: 0.7582 - accuracy: 0.5075 - val_loss: 0.6613 - val_accuracy: 0.6017\n",
      "Epoch 2/50\n",
      "4250/4250 [==============================] - 35s 8ms/step - loss: 0.6061 - accuracy: 0.6797 - val_loss: 0.5621 - val_accuracy: 0.7415\n",
      "Epoch 3/50\n",
      "4250/4250 [==============================] - 44s 10ms/step - loss: 0.5339 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.8173\n",
      "Epoch 4/50\n",
      "4250/4250 [==============================] - 56s 13ms/step - loss: 0.4919 - accuracy: 0.8326 - val_loss: 0.4741 - val_accuracy: 0.8511\n",
      "Epoch 5/50\n",
      "4250/4250 [==============================] - 34s 8ms/step - loss: 0.4645 - accuracy: 0.8527 - val_loss: 0.4511 - val_accuracy: 0.8605\n",
      "Epoch 6/50\n",
      "4250/4250 [==============================] - 34s 8ms/step - loss: 0.4453 - accuracy: 0.8578 - val_loss: 0.4342 - val_accuracy: 0.8626\n",
      "Epoch 7/50\n",
      "4250/4250 [==============================] - 69s 16ms/step - loss: 0.4308 - accuracy: 0.8592 - val_loss: 0.4212 - val_accuracy: 0.8630\n",
      "Epoch 8/50\n",
      "4250/4250 [==============================] - 45s 11ms/step - loss: 0.4197 - accuracy: 0.8594 - val_loss: 0.4110 - val_accuracy: 0.8631\n",
      "Epoch 9/50\n",
      "4250/4250 [==============================] - 71s 17ms/step - loss: 0.4109 - accuracy: 0.8595 - val_loss: 0.4029 - val_accuracy: 0.8632\n",
      "Epoch 10/50\n",
      "4250/4250 [==============================] - 56s 13ms/step - loss: 0.4037 - accuracy: 0.8595 - val_loss: 0.3962 - val_accuracy: 0.8632\n",
      "Epoch 11/50\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3977 - accuracy: 0.8595 - val_loss: 0.3905 - val_accuracy: 0.8632\n",
      "Epoch 12/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3926 - accuracy: 0.8595 - val_loss: 0.3856 - val_accuracy: 0.8632\n",
      "Epoch 13/50\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3882 - accuracy: 0.8595 - val_loss: 0.3814 - val_accuracy: 0.8632\n",
      "Epoch 14/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3844 - accuracy: 0.8595 - val_loss: 0.3777 - val_accuracy: 0.8632\n",
      "Epoch 15/50\n",
      "4250/4250 [==============================] - 23s 5ms/step - loss: 0.3810 - accuracy: 0.8595 - val_loss: 0.3744 - val_accuracy: 0.8632\n",
      "Epoch 16/50\n",
      "4250/4250 [==============================] - 26s 6ms/step - loss: 0.3780 - accuracy: 0.8596 - val_loss: 0.3715 - val_accuracy: 0.8632\n",
      "Epoch 17/50\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3753 - accuracy: 0.8596 - val_loss: 0.3689 - val_accuracy: 0.8632\n",
      "Epoch 18/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3729 - accuracy: 0.8596 - val_loss: 0.3665 - val_accuracy: 0.8632\n",
      "Epoch 19/50\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3708 - accuracy: 0.8596 - val_loss: 0.3644 - val_accuracy: 0.8632\n",
      "Epoch 20/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3688 - accuracy: 0.8596 - val_loss: 0.3625 - val_accuracy: 0.8632\n",
      "Epoch 21/50\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.3670 - accuracy: 0.8595 - val_loss: 0.3607 - val_accuracy: 0.8631\n",
      "Epoch 22/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3654 - accuracy: 0.8595 - val_loss: 0.3591 - val_accuracy: 0.8631\n",
      "Epoch 23/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.3639 - accuracy: 0.8595 - val_loss: 0.3576 - val_accuracy: 0.8631\n",
      "Epoch 24/50\n",
      "4250/4250 [==============================] - 15s 3ms/step - loss: 0.3625 - accuracy: 0.8595 - val_loss: 0.3562 - val_accuracy: 0.8631\n",
      "Epoch 25/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3613 - accuracy: 0.8595 - val_loss: 0.3549 - val_accuracy: 0.8632\n",
      "Epoch 26/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3601 - accuracy: 0.8595 - val_loss: 0.3537 - val_accuracy: 0.8631\n",
      "Epoch 27/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3590 - accuracy: 0.8595 - val_loss: 0.3526 - val_accuracy: 0.8630\n",
      "Epoch 28/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3580 - accuracy: 0.8594 - val_loss: 0.3516 - val_accuracy: 0.8630\n",
      "Epoch 29/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3570 - accuracy: 0.8594 - val_loss: 0.3506 - val_accuracy: 0.8630\n",
      "Epoch 30/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3561 - accuracy: 0.8594 - val_loss: 0.3497 - val_accuracy: 0.8630\n",
      "Epoch 31/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3553 - accuracy: 0.8594 - val_loss: 0.3489 - val_accuracy: 0.8630\n",
      "Epoch 32/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3545 - accuracy: 0.8594 - val_loss: 0.3480 - val_accuracy: 0.8631\n",
      "Epoch 33/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3538 - accuracy: 0.8593 - val_loss: 0.3473 - val_accuracy: 0.8630\n",
      "Epoch 34/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3530 - accuracy: 0.8594 - val_loss: 0.3465 - val_accuracy: 0.8630\n",
      "Epoch 35/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3524 - accuracy: 0.8594 - val_loss: 0.3458 - val_accuracy: 0.8631\n",
      "Epoch 36/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3517 - accuracy: 0.8594 - val_loss: 0.3452 - val_accuracy: 0.8631\n",
      "Epoch 37/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3511 - accuracy: 0.8594 - val_loss: 0.3445 - val_accuracy: 0.8631\n",
      "Epoch 38/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3505 - accuracy: 0.8594 - val_loss: 0.3439 - val_accuracy: 0.8631\n",
      "Epoch 39/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3499 - accuracy: 0.8594 - val_loss: 0.3433 - val_accuracy: 0.8631\n",
      "Epoch 40/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3494 - accuracy: 0.8594 - val_loss: 0.3427 - val_accuracy: 0.8632\n",
      "Epoch 41/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3489 - accuracy: 0.8594 - val_loss: 0.3422 - val_accuracy: 0.8632\n",
      "Epoch 42/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3484 - accuracy: 0.8593 - val_loss: 0.3417 - val_accuracy: 0.8633\n",
      "Epoch 43/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.3479 - accuracy: 0.8593 - val_loss: 0.3412 - val_accuracy: 0.8632\n",
      "Epoch 44/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3474 - accuracy: 0.8594 - val_loss: 0.3407 - val_accuracy: 0.8633\n",
      "Epoch 45/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3469 - accuracy: 0.8595 - val_loss: 0.3402 - val_accuracy: 0.8634\n",
      "Epoch 46/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3465 - accuracy: 0.8595 - val_loss: 0.3397 - val_accuracy: 0.8634\n",
      "Epoch 47/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3461 - accuracy: 0.8595 - val_loss: 0.3393 - val_accuracy: 0.8634\n",
      "Epoch 48/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3456 - accuracy: 0.8595 - val_loss: 0.3389 - val_accuracy: 0.8633\n",
      "Epoch 49/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3452 - accuracy: 0.8594 - val_loss: 0.3384 - val_accuracy: 0.8634\n",
      "Epoch 50/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.3448 - accuracy: 0.8594 - val_loss: 0.3380 - val_accuracy: 0.8635\n",
      "ACCURACY: 0.8599416587827183\n",
      "SGD binary_crossentropy 0.0001 64 50\n",
      "Epoch 1/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 1.1320 - accuracy: 0.1948 - val_loss: 1.0037 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.9153 - accuracy: 0.3432 - val_loss: 0.8414 - val_accuracy: 0.4297\n",
      "Epoch 3/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.7881 - accuracy: 0.5087 - val_loss: 0.7419 - val_accuracy: 0.5743\n",
      "Epoch 4/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.7072 - accuracy: 0.6276 - val_loss: 0.6760 - val_accuracy: 0.6731\n",
      "Epoch 5/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.6521 - accuracy: 0.7109 - val_loss: 0.6294 - val_accuracy: 0.7414\n",
      "Epoch 6/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.6122 - accuracy: 0.7666 - val_loss: 0.5947 - val_accuracy: 0.7869\n",
      "Epoch 7/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.5819 - accuracy: 0.8008 - val_loss: 0.5678 - val_accuracy: 0.8163\n",
      "Epoch 8/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.5581 - accuracy: 0.8226 - val_loss: 0.5463 - val_accuracy: 0.8327\n",
      "Epoch 9/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.5388 - accuracy: 0.8358 - val_loss: 0.5285 - val_accuracy: 0.8441\n",
      "Epoch 10/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.5228 - accuracy: 0.8440 - val_loss: 0.5137 - val_accuracy: 0.8513\n",
      "Epoch 11/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.5093 - accuracy: 0.8492 - val_loss: 0.5011 - val_accuracy: 0.8549\n",
      "Epoch 12/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4978 - accuracy: 0.8523 - val_loss: 0.4903 - val_accuracy: 0.8572\n",
      "Epoch 13/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4879 - accuracy: 0.8545 - val_loss: 0.4809 - val_accuracy: 0.8592\n",
      "Epoch 14/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4792 - accuracy: 0.8562 - val_loss: 0.4726 - val_accuracy: 0.8601\n",
      "Epoch 15/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4716 - accuracy: 0.8569 - val_loss: 0.4653 - val_accuracy: 0.8609\n",
      "Epoch 16/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4649 - accuracy: 0.8578 - val_loss: 0.4588 - val_accuracy: 0.8614\n",
      "Epoch 17/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4589 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8619\n",
      "Epoch 18/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4535 - accuracy: 0.8587 - val_loss: 0.4479 - val_accuracy: 0.8625\n",
      "Epoch 19/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4487 - accuracy: 0.8591 - val_loss: 0.4432 - val_accuracy: 0.8627\n",
      "Epoch 20/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4444 - accuracy: 0.8592 - val_loss: 0.4390 - val_accuracy: 0.8629\n",
      "Epoch 21/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4405 - accuracy: 0.8593 - val_loss: 0.4351 - val_accuracy: 0.8631\n",
      "Epoch 22/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4369 - accuracy: 0.8594 - val_loss: 0.4316 - val_accuracy: 0.8631\n",
      "Epoch 23/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4336 - accuracy: 0.8596 - val_loss: 0.4284 - val_accuracy: 0.8630\n",
      "Epoch 24/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4306 - accuracy: 0.8596 - val_loss: 0.4254 - val_accuracy: 0.8631\n",
      "Epoch 25/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4279 - accuracy: 0.8596 - val_loss: 0.4227 - val_accuracy: 0.8633\n",
      "Epoch 26/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4254 - accuracy: 0.8597 - val_loss: 0.4202 - val_accuracy: 0.8633\n",
      "Epoch 27/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4230 - accuracy: 0.8597 - val_loss: 0.4179 - val_accuracy: 0.8633\n",
      "Epoch 28/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4209 - accuracy: 0.8597 - val_loss: 0.4157 - val_accuracy: 0.8633\n",
      "Epoch 29/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4189 - accuracy: 0.8598 - val_loss: 0.4137 - val_accuracy: 0.8633\n",
      "Epoch 30/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4170 - accuracy: 0.8598 - val_loss: 0.4119 - val_accuracy: 0.8633\n",
      "Epoch 31/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4152 - accuracy: 0.8598 - val_loss: 0.4101 - val_accuracy: 0.8633\n",
      "Epoch 32/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4136 - accuracy: 0.8598 - val_loss: 0.4084 - val_accuracy: 0.8633\n",
      "Epoch 33/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4120 - accuracy: 0.8598 - val_loss: 0.4069 - val_accuracy: 0.8634\n",
      "Epoch 34/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4106 - accuracy: 0.8599 - val_loss: 0.4054 - val_accuracy: 0.8635\n",
      "Epoch 35/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4092 - accuracy: 0.8599 - val_loss: 0.4040 - val_accuracy: 0.8635\n",
      "Epoch 36/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4078 - accuracy: 0.8600 - val_loss: 0.4027 - val_accuracy: 0.8635\n",
      "Epoch 37/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.4066 - accuracy: 0.8599 - val_loss: 0.4014 - val_accuracy: 0.8635\n",
      "Epoch 38/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4054 - accuracy: 0.8600 - val_loss: 0.4002 - val_accuracy: 0.8634\n",
      "Epoch 39/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4043 - accuracy: 0.8600 - val_loss: 0.3990 - val_accuracy: 0.8634\n",
      "Epoch 40/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4031 - accuracy: 0.8600 - val_loss: 0.3979 - val_accuracy: 0.8634\n",
      "Epoch 41/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4021 - accuracy: 0.8600 - val_loss: 0.3968 - val_accuracy: 0.8634\n",
      "Epoch 42/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4011 - accuracy: 0.8600 - val_loss: 0.3957 - val_accuracy: 0.8635\n",
      "Epoch 43/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.4001 - accuracy: 0.8601 - val_loss: 0.3947 - val_accuracy: 0.8634\n",
      "Epoch 44/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.3991 - accuracy: 0.8600 - val_loss: 0.3938 - val_accuracy: 0.8635\n",
      "Epoch 45/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3982 - accuracy: 0.8601 - val_loss: 0.3928 - val_accuracy: 0.8635\n",
      "Epoch 46/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3973 - accuracy: 0.8601 - val_loss: 0.3919 - val_accuracy: 0.8635\n",
      "Epoch 47/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.3964 - accuracy: 0.8601 - val_loss: 0.3910 - val_accuracy: 0.8635\n",
      "Epoch 48/50\n",
      "2125/2125 [==============================] - 7s 3ms/step - loss: 0.3955 - accuracy: 0.8602 - val_loss: 0.3901 - val_accuracy: 0.8635\n",
      "Epoch 49/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3947 - accuracy: 0.8602 - val_loss: 0.3893 - val_accuracy: 0.8635\n",
      "Epoch 50/50\n",
      "2125/2125 [==============================] - 6s 3ms/step - loss: 0.3938 - accuracy: 0.8601 - val_loss: 0.3884 - val_accuracy: 0.8636\n",
      "ACCURACY: 0.8609665720592873\n",
      "SGD binary_crossentropy 0.0001 128 50\n",
      "Epoch 1/50\n",
      "1063/1063 [==============================] - 4s 4ms/step - loss: 1.0533 - accuracy: 0.2657 - val_loss: 0.9920 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.9365 - accuracy: 0.4035 - val_loss: 0.8899 - val_accuracy: 0.4691\n",
      "Epoch 3/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.8481 - accuracy: 0.5207 - val_loss: 0.8119 - val_accuracy: 0.5642\n",
      "Epoch 4/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.7801 - accuracy: 0.6041 - val_loss: 0.7513 - val_accuracy: 0.6370\n",
      "Epoch 5/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.7267 - accuracy: 0.6697 - val_loss: 0.7032 - val_accuracy: 0.6950\n",
      "Epoch 6/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.6841 - accuracy: 0.7192 - val_loss: 0.6646 - val_accuracy: 0.7387\n",
      "Epoch 7/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.6496 - accuracy: 0.7555 - val_loss: 0.6332 - val_accuracy: 0.7698\n",
      "Epoch 8/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.6213 - accuracy: 0.7802 - val_loss: 0.6071 - val_accuracy: 0.7912\n",
      "Epoch 9/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5978 - accuracy: 0.7978 - val_loss: 0.5854 - val_accuracy: 0.8069\n",
      "Epoch 10/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5781 - accuracy: 0.8111 - val_loss: 0.5670 - val_accuracy: 0.8190\n",
      "Epoch 11/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5613 - accuracy: 0.8214 - val_loss: 0.5512 - val_accuracy: 0.8293\n",
      "Epoch 12/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5468 - accuracy: 0.8301 - val_loss: 0.5376 - val_accuracy: 0.8376\n",
      "Epoch 13/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5343 - accuracy: 0.8374 - val_loss: 0.5258 - val_accuracy: 0.8439\n",
      "Epoch 14/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5234 - accuracy: 0.8429 - val_loss: 0.5154 - val_accuracy: 0.8492\n",
      "Epoch 15/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5138 - accuracy: 0.8471 - val_loss: 0.5062 - val_accuracy: 0.8525\n",
      "Epoch 16/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.5053 - accuracy: 0.8496 - val_loss: 0.4980 - val_accuracy: 0.8542\n",
      "Epoch 17/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4977 - accuracy: 0.8521 - val_loss: 0.4907 - val_accuracy: 0.8565\n",
      "Epoch 18/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4909 - accuracy: 0.8535 - val_loss: 0.4841 - val_accuracy: 0.8584\n",
      "Epoch 19/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4846 - accuracy: 0.8548 - val_loss: 0.4780 - val_accuracy: 0.8595\n",
      "Epoch 20/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4790 - accuracy: 0.8559 - val_loss: 0.4725 - val_accuracy: 0.8605\n",
      "Epoch 21/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4738 - accuracy: 0.8568 - val_loss: 0.4674 - val_accuracy: 0.8612\n",
      "Epoch 22/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4690 - accuracy: 0.8572 - val_loss: 0.4627 - val_accuracy: 0.8616\n",
      "Epoch 23/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4646 - accuracy: 0.8578 - val_loss: 0.4584 - val_accuracy: 0.8621\n",
      "Epoch 24/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4605 - accuracy: 0.8581 - val_loss: 0.4543 - val_accuracy: 0.8621\n",
      "Epoch 25/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4567 - accuracy: 0.8586 - val_loss: 0.4505 - val_accuracy: 0.8626\n",
      "Epoch 26/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4531 - accuracy: 0.8588 - val_loss: 0.4470 - val_accuracy: 0.8628\n",
      "Epoch 27/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4497 - accuracy: 0.8590 - val_loss: 0.4436 - val_accuracy: 0.8628\n",
      "Epoch 28/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4465 - accuracy: 0.8592 - val_loss: 0.4404 - val_accuracy: 0.8631\n",
      "Epoch 29/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4435 - accuracy: 0.8592 - val_loss: 0.4374 - val_accuracy: 0.8630\n",
      "Epoch 30/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4406 - accuracy: 0.8593 - val_loss: 0.4345 - val_accuracy: 0.8632\n",
      "Epoch 31/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4379 - accuracy: 0.8593 - val_loss: 0.4318 - val_accuracy: 0.8632\n",
      "Epoch 32/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4353 - accuracy: 0.8593 - val_loss: 0.4292 - val_accuracy: 0.8632\n",
      "Epoch 33/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4328 - accuracy: 0.8594 - val_loss: 0.4267 - val_accuracy: 0.8633\n",
      "Epoch 34/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4304 - accuracy: 0.8594 - val_loss: 0.4243 - val_accuracy: 0.8633\n",
      "Epoch 35/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4281 - accuracy: 0.8594 - val_loss: 0.4220 - val_accuracy: 0.8633\n",
      "Epoch 36/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4259 - accuracy: 0.8595 - val_loss: 0.4197 - val_accuracy: 0.8634\n",
      "Epoch 37/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4237 - accuracy: 0.8595 - val_loss: 0.4176 - val_accuracy: 0.8635\n",
      "Epoch 38/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4217 - accuracy: 0.8596 - val_loss: 0.4155 - val_accuracy: 0.8635\n",
      "Epoch 39/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4197 - accuracy: 0.8596 - val_loss: 0.4135 - val_accuracy: 0.8635\n",
      "Epoch 40/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4178 - accuracy: 0.8595 - val_loss: 0.4116 - val_accuracy: 0.8635\n",
      "Epoch 41/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4159 - accuracy: 0.8596 - val_loss: 0.4098 - val_accuracy: 0.8634\n",
      "Epoch 42/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4142 - accuracy: 0.8596 - val_loss: 0.4080 - val_accuracy: 0.8634\n",
      "Epoch 43/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4124 - accuracy: 0.8596 - val_loss: 0.4062 - val_accuracy: 0.8635\n",
      "Epoch 44/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4108 - accuracy: 0.8596 - val_loss: 0.4045 - val_accuracy: 0.8635\n",
      "Epoch 45/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4091 - accuracy: 0.8597 - val_loss: 0.4029 - val_accuracy: 0.8635\n",
      "Epoch 46/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4076 - accuracy: 0.8597 - val_loss: 0.4013 - val_accuracy: 0.8634\n",
      "Epoch 47/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4060 - accuracy: 0.8597 - val_loss: 0.3998 - val_accuracy: 0.8634\n",
      "Epoch 48/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4046 - accuracy: 0.8597 - val_loss: 0.3983 - val_accuracy: 0.8634\n",
      "Epoch 49/50\n",
      "1063/1063 [==============================] - 4s 3ms/step - loss: 0.4031 - accuracy: 0.8597 - val_loss: 0.3969 - val_accuracy: 0.8633\n",
      "Epoch 50/50\n",
      "1063/1063 [==============================] - 3s 3ms/step - loss: 0.4018 - accuracy: 0.8597 - val_loss: 0.3955 - val_accuracy: 0.8634\n",
      "ACCURACY: 0.8609862819299905\n",
      "SGD mean_squared_error 0.01 32 50\n",
      "Epoch 1/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.1140 - accuracy: 0.8596 - val_loss: 0.1061 - val_accuracy: 0.8632\n",
      "Epoch 2/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1069 - accuracy: 0.8596 - val_loss: 0.1032 - val_accuracy: 0.8632\n",
      "Epoch 3/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1049 - accuracy: 0.8596 - val_loss: 0.1017 - val_accuracy: 0.8632\n",
      "Epoch 4/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1037 - accuracy: 0.8596 - val_loss: 0.1008 - val_accuracy: 0.8632\n",
      "Epoch 5/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.1030 - accuracy: 0.8596 - val_loss: 0.1002 - val_accuracy: 0.8632\n",
      "Epoch 6/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.1024 - accuracy: 0.8596 - val_loss: 0.0996 - val_accuracy: 0.8632\n",
      "Epoch 7/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1020 - accuracy: 0.8596 - val_loss: 0.0992 - val_accuracy: 0.8632\n",
      "Epoch 8/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1016 - accuracy: 0.8596 - val_loss: 0.0989 - val_accuracy: 0.8632\n",
      "Epoch 9/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1013 - accuracy: 0.8596 - val_loss: 0.0986 - val_accuracy: 0.8632\n",
      "Epoch 10/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1010 - accuracy: 0.8596 - val_loss: 0.0983 - val_accuracy: 0.8632\n",
      "Epoch 11/50\n",
      "4250/4250 [==============================] - 13s 3ms/step - loss: 0.1008 - accuracy: 0.8596 - val_loss: 0.0981 - val_accuracy: 0.8632\n",
      "Epoch 12/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.1006 - accuracy: 0.8596 - val_loss: 0.0979 - val_accuracy: 0.8632\n",
      "Epoch 13/50\n",
      "4250/4250 [==============================] - 9s 2ms/step - loss: 0.1003 - accuracy: 0.8596 - val_loss: 0.0977 - val_accuracy: 0.8632\n",
      "Epoch 14/50\n",
      "4250/4250 [==============================] - 8s 2ms/step - loss: 0.1002 - accuracy: 0.8596 - val_loss: 0.0975 - val_accuracy: 0.8632\n",
      "Epoch 15/50\n",
      "4250/4250 [==============================] - 369s 87ms/step - loss: 0.1000 - accuracy: 0.8596 - val_loss: 0.0974 - val_accuracy: 0.8632\n",
      "Epoch 16/50\n",
      "4250/4250 [==============================] - 27s 6ms/step - loss: 0.0999 - accuracy: 0.8596 - val_loss: 0.0972 - val_accuracy: 0.8632\n",
      "Epoch 17/50\n",
      "4250/4250 [==============================] - 82s 19ms/step - loss: 0.0997 - accuracy: 0.8596 - val_loss: 0.0971 - val_accuracy: 0.8632\n",
      "Epoch 18/50\n",
      "4250/4250 [==============================] - 29s 7ms/step - loss: 0.0996 - accuracy: 0.8596 - val_loss: 0.0970 - val_accuracy: 0.8632\n",
      "Epoch 19/50\n",
      "4250/4250 [==============================] - 592s 139ms/step - loss: 0.0995 - accuracy: 0.8599 - val_loss: 0.0969 - val_accuracy: 0.8632\n",
      "Epoch 20/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.0994 - accuracy: 0.8629 - val_loss: 0.0968 - val_accuracy: 0.8667\n",
      "Epoch 21/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.0993 - accuracy: 0.8634 - val_loss: 0.0967 - val_accuracy: 0.8666\n",
      "Epoch 22/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.0992 - accuracy: 0.8636 - val_loss: 0.0966 - val_accuracy: 0.8670\n",
      "Epoch 23/50\n",
      "4250/4250 [==============================] - 17s 4ms/step - loss: 0.0991 - accuracy: 0.8637 - val_loss: 0.0966 - val_accuracy: 0.8670\n",
      "Epoch 24/50\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.0991 - accuracy: 0.8636 - val_loss: 0.0965 - val_accuracy: 0.8672\n",
      "Epoch 25/50\n",
      "4250/4250 [==============================] - 16s 4ms/step - loss: 0.0990 - accuracy: 0.8638 - val_loss: 0.0964 - val_accuracy: 0.8673\n",
      "Epoch 26/50\n",
      "4250/4250 [==============================] - 15s 4ms/step - loss: 0.0989 - accuracy: 0.8639 - val_loss: 0.0964 - val_accuracy: 0.8674\n",
      "Epoch 27/50\n",
      "4250/4250 [==============================] - 14s 3ms/step - loss: 0.0989 - accuracy: 0.8640 - val_loss: 0.0963 - val_accuracy: 0.8673\n",
      "Epoch 28/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.0988 - accuracy: 0.8641 - val_loss: 0.0963 - val_accuracy: 0.8674\n",
      "Epoch 29/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.0988 - accuracy: 0.8643 - val_loss: 0.0962 - val_accuracy: 0.8672\n",
      "Epoch 30/50\n",
      "4250/4250 [==============================] - 10s 2ms/step - loss: 0.0987 - accuracy: 0.8644 - val_loss: 0.0962 - val_accuracy: 0.8674\n",
      "Epoch 31/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.0987 - accuracy: 0.8644 - val_loss: 0.0961 - val_accuracy: 0.8676\n",
      "Epoch 32/50\n",
      "4250/4250 [==============================] - 11s 3ms/step - loss: 0.0987 - accuracy: 0.8647 - val_loss: 0.0961 - val_accuracy: 0.8675\n",
      "Epoch 33/50\n",
      "4250/4250 [==============================] - 12s 3ms/step - loss: 0.0986 - accuracy: 0.8649 - val_loss: 0.0961 - val_accuracy: 0.8675\n",
      "Epoch 34/50\n",
      "4250/4250 [==============================] - 10s 2ms/step - loss: 0.0986 - accuracy: 0.8649 - val_loss: 0.0961 - val_accuracy: 0.8676\n",
      "Epoch 35/50\n",
      "1499/4250 [=========>....................] - ETA: 9s - loss: 0.0985 - accuracy: 0.8645"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xb/vhz5bjxd7wbg6jqh2txpp0vh0000gn/T/ipykernel_815/1283933356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;34m'''Fitting ANN'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;34m'''Predicting'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Optimizing using Grid Search'''\n",
    "# will take hours to run \n",
    "\n",
    "results = []\n",
    "\n",
    "Optimizer = ['SGD','Adam']\n",
    "Loss_Function = ['binary_crossentropy','mean_squared_error']\n",
    "Learning_Rate = [.01,.001,.0001]\n",
    "Batch_Size = [32,64,128]\n",
    "Nodes = [6,8,10]\n",
    "Epochs = [50]\n",
    "\n",
    "for optimizer in Optimizer:\n",
    "    for loss in Loss_Function:\n",
    "        for lr in Learning_Rate:\n",
    "            for bs in Batch_Size:\n",
    "                for epoch in Epochs:\n",
    "                    \n",
    "                    print(optimizer, loss, lr, bs, epoch)\n",
    "\n",
    "                    '''Compiling ANN'''\n",
    "                    ann = keras_model()\n",
    "\n",
    "                    if optimizer == 'Adam':\n",
    "                        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                    else:\n",
    "                        opt = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "                    \n",
    "                    ann.compile(optimizer=opt,\n",
    "                                loss=loss,\n",
    "                                metrics=['accuracy'])\n",
    "\n",
    "                    '''Fitting ANN'''\n",
    "                    history = ann.fit(X_train, y_train, validation_split=0.33, batch_size=bs,epochs = epoch)\n",
    "\n",
    "                    '''Predicting'''\n",
    "                    y_pred = ann.predict(X_test)\n",
    "                    y_pred[y_pred <= 0.5] = 0.\n",
    "                    y_pred[y_pred > 0.5] = 1.\n",
    "                    acc = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    print('ACCURACY:', acc)\n",
    "                    results.append([(optimizer, loss, lr, bs, epoch, acc)])\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('SGD', 'binary_crossentropy', 0.01, 32, 50, 0.8656575212866604)], [('SGD', 'binary_crossentropy', 0.01, 64, 50, 0.8653224534847052)], [('SGD', 'binary_crossentropy', 0.01, 128, 50, 0.8652041942604857)], [('SGD', 'binary_crossentropy', 0.001, 32, 50, 0.8646523178807947)], [('SGD', 'binary_crossentropy', 0.001, 64, 50, 0.8618338063702302)], [('SGD', 'binary_crossentropy', 0.001, 128, 50, 0.8610059918006938)], [('SGD', 'binary_crossentropy', 0.0001, 32, 50, 0.8599416587827183)], [('SGD', 'binary_crossentropy', 0.0001, 64, 50, 0.8609665720592873)], [('SGD', 'binary_crossentropy', 0.0001, 128, 50, 0.8609862819299905)]]\n"
     ]
    }
   ],
   "source": [
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61315cc2b9077d4ce1982e9f0ae67cfc2b9596d4e144604e26683e4a9acd7382"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
